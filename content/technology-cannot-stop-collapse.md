
---
author: Jason Godesky
comments: true
date: 2005-11-02T00:00:00-05:00
slug: technology-cannot-stop-collapse
title: "Thesis #16: Technology cannot stop collapse"
---

Invariably, the threat of our own civilization's collapse is readily answered with the hope of technological progress. Progressivists deny that we face any systemic problems, only technical problems, with technical solutions. As we have seen in the previous theses, this is most certainly not the case, but the question remains: could these systemic problems be solved through the proper application of technology? Technophiliacs and techno-utopians often wax poetic for the prospects of our technological future. Science fiction like *Star Trek* often portrays this vision, where technology has solved all of our problems. But ultimately, such hopes are statements of belief, not fact--and a belief that is not very well-grounded in reality, at that.

Primitivists often define themselves in regard to their dim view of technology, but they inherit from this a Romantic idea of "technology" as referring solely to the metal machines of the Industrial Revolution. The genus *Homo* is separated from the Australopithecines by our use of tools. The creation of stone technology led to handedness, and was closely related to an expansion in cranium capacity, and the development of the areas of the brain used for language. Humans make technology, but to a significant extent, technology also made us. A *complete* rejection of *all* technology is a rejection of ourselves. Most of the great apes make and use tools. Even crows have technology. Obviously, there are sustainable levels of technology.

However, since the Enlightenment, most of our thinking about technology has been set by a different idea, the notion of unbounded progress, which is just as flawed. Foragers evidence little concern for the sweep of history. There is a certain sense of a timeless present in many such societies. Very often, there is only two real time periods--the present, and the mythic past. The Australian concept of the Dreamtime highlights how different forager conceptions of time can be--the Dreamtime is, simultaneously, the distant past, and coterminous with the present. Other societies, primarily agrarian, developed ideas of cyclical time. The best known of these systems is likely the Mayan and Aztec calendars, that charted out history in the same kind of cycles that governed the passage of days, seasons and years on a larger, historical level. Much more prevalent in past civilizations, however, has been a sense of degradation, of a lost "golden age," and the impression that the present is inferior to the past. This idea is found strongly in Greek and Hebrew beliefs. The idea of history as the story of human progress is largely a result of the Enlightenment, though it would be a mistake to claim it was entirely unrepresented before that. Robert Nisbet's "[The Idea of Progress](http://oll.libertyfund.org/Essays/Bibliographical/Nisbet0190/Progress.html)" highlights the pre-modern history of this notion. He concludes:

> As I have shown, the Western idea of progress was born of Greek imagery, religious in foundation; the imagery of growth. It attained its fullness within Christianity, starting with the Church Fathers, especially Augustine. Central to any genuinely Christian form of religion is the Pauline emphasis upon hope: hope to be given gratification in this world as well as the next. Basically, the Christian creed, its concept of Original Sin notwithstanding, is inseparable from a philosophy of history that is overwhelmingly optimistic about man's estate in this world and the next, provided only that due deference and commitment to God are given.

This highlights the essentially religious nature of such belief in progress, no less religious than previous ideas about history as regress, or history as cyclical. While science itself may be wholly secular, the religious faith *in* science--and the salvific hope of future progress, *thanks* to science--is anything but. August Comte was more honest with himself than most of his contemporary fellows in his attempts to found the "Positivist *Church*."

In *[Collapse](http://www.amazon.com/exec/obidos/ASIN/0670033375/anthropik-20 "Buy it from Amazon.com here and help out the Tribe of Anthropik!")*, Diamond refutes a number of "one-liner" objections, including "Technology will solve our problems," saying:

> This is an expression of faith about the future, and therefore based on a supposed track record of technology having solved more problems than it created in the recent past. Underlying this expression of faith is the implicit assumption that, from tomorrow onwards, technology will function primarily to solve existing problems and will cease to create new problems. Those with such faith also assume that the new technologies now under discussion will succeed, and that they will do so quickly enough to make a big difference soon. In extended conversations that I had with two of America's most successful and best-known businessmen and financiers, both of them eloquently described to me emerging technologies and financial instruments that differ fundamentally from those of the past and that, they confidently predicted, would solve our environmental problems.
>
> But actual experience is the opposite of this assumed track record. Some dreamed-of new technologies succeed, while others don't. Those that do succeed typically take a few decades to develop and phase in widely: think of gas heating, electric lighting, cars and airplanes, television, computers, and so on. New technologies, whether or not they succeed in solving the problem that they were designed to solve, regularly create unanticipated new problems. Technological solutions to environmental problems are routinely far more expensive than preventive measures to avoid creating the problem in the first place: for example, the billions of dollars of damages and clean-up costs associated with major oil spills, compared to the modest cost of safety measures effective at minimizing the risks of a major oil spill.
>
> Most of all, advances in technology just increase our ability to do things, which may be either for the better or for the worse. All of our current problems are unintended negative consequences of our existing technology. The rapid advances in technology during the twentieth century have been creating difficult new problems faster than they have been solving old problems: that's why we're in the situation in which we now find ourselves. What makes you think that, as of January 1, 2006, for the first time in human history, technology will miraculously stop causing new unanticipated problems while it solves just the problems that it previously produced?

Diamond is touching on the first factor that makes technical solutions so ambiguous: unintended consequences. Diamond goes on to discuss the effects that CFC's have had on our atmosphere, but other examples abound--and not all of them negative. Benedictine monks invented the clock to help maintain their schedule of prayers, but, as Mumford put it, "Time-keeping passed into time-serving and time-accounting and time-rationing. As this took place, Eternity ceased gradually to serve as the measure and focus of human actions." Johannes Gutenberg was a devout Catholic, but, as Diamond discusses in *[Guns, Germs & Steel](http://www.amazon.com/exec/obidos/ASIN/0393317552/anthropik-20 "Buy it from Amazon.com here and help out the Tribe of Anthropik!")*, the printing press helped create a shared linguistic world which, manipulated by politicians lke Ferdinand and Isabella of Spain, resulted in the myth of the "Nation." Bronze casting techniques invented for church bells revolutionized warfare by allowing the producton of bronze cannons. Science historian James Burke's 1978 television documentary series, *[Connections](http://www.imdb.com/title/tt0078588/ "IMDB entry")*, presented the entire history of invention in terms of such unintended consequences, with the unintended consequences of one invention precipitating the next.

The problem with unintended consequences, however, is that since they are unintended, they can be good, bad, or indifferent. While we can certainly characterize any of the unintended consequences above as "good," there are others which are much less clear. The hygenic advances of the 1900s reduced diseases like cholera, cleaned up the cities, and had more to do with the extension of the industrialized life span than any of our investments in medical technology. However, the cities became *so* clean, it allowed a previously endemic disease to become epidemic. For the first two weeks after birth, a baby still has the mother's antibodies in its bloodstream. After two weeks, those are cycled out, and the baby relies on its own antibodies. Any pathogens the baby encounters in those two weeks will be counteracted by the mother's antibodies, and so, carries a low risk of actual illness. However, that exposure will allow the baby to begin creating her own antibodies to it. This is why *poliovirus* spent so many millennia endemic to humans. It is a relatively weak virus, but once the cities became sufficiently clean and babies were no longer encountering it in their first two weeks, an entire generaton grew up with no immunity to polio whatsoever. Though polio never achieved the truly terrifying numbers we normally associate with an epidemic, the personal toll the disease took on its victims created a pervasive aura of fear. The polio epidemics of the twentieth century were an unintended consequence of the hygenic advances of the decades prior.

This set the stage for what is perhaps the most clear-cut success story of Western biomedicine, alongside the eradication of smallpox: the polio vaccine. Yet the polio vaccine is not without its own unintended consequences. Though far from proven, it is possible that [the research for a polio vaccine created AIDS](http://www.uow.edu.au/arts/sts/bmartin/dissent/documents/AIDS/). We know that the monkey tissue cultures used to develop the polio vaccine (for which Ender recieved the Nobel Prize in 1954, the same year Jonas Salk used the technique to develop the first working vaccine) introduced a number of simian virii (SV's) into the human population on a large scale for the first time. It is known now, for example, that SV40 went undetected in the first years of the polio vaccine, contributing to many patients developing cancer later in life. This, too, was an unintended consequence--SV40 went undetected because is was unknown at the time, and thus, impossible to test for. There is some indication that AIDS may have been caused similarly: by introducing a simian virus into a large human population, early polio vaccine trials in the Belgian Congo *may*have provided the perfect environment for such a simian virus to jump the species barrier and mutate into HIV as we know it today. To date, this theory has not yet been properly investigated, so conclusive evidence is lacking.

Bill Joy was one of the co-founders of Sun Microsystems in 1984, its chief scientist until 2003, and the programmer responsible for BSD. In short, he is one of the greatest innovators of new technology in computer engineering--itself the field of technology which still shows the greatest potential for future growth. Yet Joy's 2000 article for *Wired* magazine (according to Wikipedia, the "Bible" of techno-utopians), "[Why the Future Doesn't Need Us](http://www.wired.com/wired/archive/8.04/joy_pr.html)," has become a significant work for *primitivist* thought. After a quotation from the Unabomber's manifesto, Joy writes:

> I am no apologist for Kaczynski. His bombs killed three people during a 17-year terror campaign and wounded many others. One of his bombs gravely injured my friend David Gelernter, one of the most brilliant and visionary computer scientists of our time. Like many of my colleagues, I felt that I could easily have been the Unabomber's next target.
>
> Kaczynski's actions were murderous and, in my view, criminally insane. He is clearly a Luddite, but simply saying this does not dismiss his argument; as difficult as it is for me to acknowledge, I saw some merit in the reasoning in this single passage. I felt compelled to confront it.
>
> Kaczynski's dystopian vision describes unintended consequences, a well-known problem with the design and use of technology, and one that is clearly related to Murphy's law - "Anything that can go wrong, will." (Actually, this is Finagle's law, which in itself shows that Finagle was right.) Our overuse of antibiotics has led to what may be the biggest such problem so far: the emergence of antibiotic-resistant and much more dangerous bacteria. Similar things happened when attempts to eliminate malarial mosquitoes using DDT caused them to acquire DDT resistance; malarial parasites likewise acquired multi-drug-resistant genes.

Unintended consequences, however, are hit and miss. As unlikely as it is that no future technology will ever have unintended consequences when so many past inventions have, such consequences are sometimes beneficial. If this were the only limitations to technology's role, then we would merely have to be more careful with our innovation; it would not eliminate the possibility of a technical solution. However, unintended consequences is not the only, nor even the most pressing, limitation that technology faces.

William Stanley Jevons is a seminal figure in economics. He helped formulate the very theory of marginal returns which, as we saw in [thesis #14]({{< relref "complexity-is-subject-to-diminishing-returns.md">}} "Thesis #14: Complexity is subject to diminishing returns."), governs complexity in general, and technological innovation specifically. In his 1865 book, *The Coal Question*, Jevons noted that the consumption of coal in England soared after James Watt introduced his steam engine. Steam engines had been used as toys as far back as ancient Greece, and Thomas Newcomen's earlier design was suitable for industrial use. Watt's invention merely made more efficient use of coal, compared to Newcomen's. This made the engine more economical, and so, touched off the Industrial Revolution--and in so doing, created the very same modern, unprecedented attitudes towards technology and invention that are now presented as hope against collapse. In the book, Jevons formulated a principle now known as "Jevons Paradox." It is not a paradox in the logical sense, but it is certainly counterintuitive. Jevons Paradox states that any technology which allows for the more efficient use of a given resource will result in *greater* use of that resource, not less. By increasing the efficiency of a resource's use, the marginal utility of that resource is increased more than enough to compensate for the fall. This is why innovations in computer technology have made for *longer* working hours, as employers expect that an employee with a technology that cuts his work in half can do three times more work. This is why more fuel-efficient vehicles have resulted in longer commutes, and the suburban sprawl that creates an automotive-centric culture, with overall *higher* petroleum use.

Most of the technologies offered as solutions to collapse expect Jevons Paradox not to hold. They recognize the crisis we face with deplenishing resources, but hope to solve that problem by making the use of that technology more efficient. Jevons Paradox illustrates precisely what the unintended consequence of such a technology will be--in these cases, *precisely the opposite* of the intended effect. Any technology that aims to save our resources by making more efficient use of them can only result in depleting those resources even more quickly.

The best hope technology can offer for staving off collapse is to tap a new energy subsidy, just as the Industrial Revolution tapped our current fossil fuel subsidy. For instance, the energy we currently use in petroleum could be matched by covering 1% of the United States' land area in photovoltaic cells. However, the hope that human population will simply "level off" due to modernization is in vain (*see* [thesis #4]({{< relref "human-population-is-a-function-of-food-supply.md">}} "Thesis #4: Human population is a function of food supply.")); human population is a function of food supply, and population will always rise to the energy level available. The shift to photovoltaics, like the shift to fossil fuels, is merely an invitation to continued growth--another "win" in the "Food Race." If our energy needs can be met by covering just 1% of the United States with photovoltaic cells, why not cover 2% and double our energy? Of course, then our population will double, and we'll need to expand again.

Such technological advances can postpone collapse, but they cannot stop it. However, there is also a cost associated with such postponements: each one makes collapse, when it eventually does happen, exponentially more destructive. Had the the timber crisis of the 1600s resulted in the collapse of Renaissance Western Europe, millions would have died, and Europe would have been ecologically ruined. New energy sources were found in New World colonies, and coal. Collapse was postponed, but the toll of collapse was increased by an order of magnitude. Now, we face a collapse that will kill billions rather than simply millions; rather than simply ravaging Europe, we have set off the single worst mass extinction in the history of the planet and set off massive global climate change, reversing a cooling trend that has guided the earth through geological time. A shift to photovoltaics would limit us only when we have covered so much of the earth's surface that there is no longer sufficient sunlight for green plants to grow--thus breaking the oxygen/carbon dioxide cycle, and damning humanity to extinction as we suffocate on our own breath.

Unless, of course, technology can deploy a solution to that, as well. That is the promise the techno-salvationist offers: to solve every problem just in the nick of time, thanks to the market forces that compel innovation, and eventually, to leave the earth behind and move from planet to planet, consuming the resources we need, and moving on. Most of them say we will "sow life throughout the universe" with such a plan, but they're neglecting a very basic fact: that our civilization is not devastating our planet because it is *evil*, but because these problems are *systemic*. Every resource has some rate at which it is replenished. Sometimes, that rate is "zero," but even fossil fuels are replenished over a sufficiently long time scale. Thus, the distinction between sustainable and unsustainable is the *rate* at which that resource is consumed--whether it is consumed faster, or slower, than it is replenished. Because complexity creates a self-reinforcing positive feedback loop (*see* [thesis #12]({{< relref "civilization-must-always-grow.md">}} "Thesis #12: Civilization must always grow.")), complexity is a function of energy, and energy is obtained from resources, even a complex society that begins with sustainable practices must eventually become unsustainable as its complexity increases, and its need for more energy grows. Thus, civilization can never spread life through the universe. The brightest hope the techno-salvationist can offer is to become the alien villains of science fiction movies like *Independence Day*.

Fortunately, such a nightmare scenario, like "the Singularity," are merely fits of techno-salvationist hyperbole. The Singularity, sometimes called "the Rapture of the Nerds," predicts that the exponential curve of technological development will continue until we reach that point where the graph most resembles a straight, vertical line, and technological innovation comes at a pace too great for anyone to predict.

The problem with this scenario is that it only looks at a small part of the graph. If we see it in its whole, we see that technological invention is not following a graph of exponential growth at all--but a curve of diminishing marginal returns. We saw this in [thesis #14]({{< relref "complexity-is-subject-to-diminishing-returns.md">}} "Thesis #14: Complexity is subject to diminishing returns."), and in [the previous thesis]({{< relref "we-have-passed-the-point-of-diminishing-returns.md">}} "Thesis #15: We have passed the point of diminishing returns."), we saw that we have *passed* the point of diminishing returns. Facile excitement about "the Singularity" is engendered by such ideas as "Moore's Law" ("computer chip performance doubles roughly every 18 months"), which remains "true" only because computer technology is younger than most other forms, and so is one of the very few areas of technological innovation still seeing significant activity--because computer technology, unlike technology in general, has *not*yet reached the point of diminishing returns. However, even here, Moore's Law is beginning to fail. In "[The Lives and Death of Moore's Law](http://firstmonday.org/issues/issue7_11/tuomi/index.html)," Ilkka Tuomi writes:

> Contrary to popular claims, it appears that the common versions of Moore's Law have not been valid during the last decades. As semiconductors are becoming important in economy and society, Moore's Law is now becoming an increasingly misleading predictor of future developments.

In [a *Business Week* article](http://www.businessweek.com/magazine/content/05_25/b3938629.htm "'More Life For Moore's Law,' Business Week, 20 June 2005"), the difficulties of maintaining that pace--and the threat of diminishing returns being reached--is raised:

> Now more than ever, though, upholding Moore's Law will require imagination. So far chip companies have relied mostly on one clever trick: They shrink the transistors on chips so that electrons have less distance to travel, thereby speeding up the processing of data. But that trick is getting harder to perform. In the 1990s, shrinking led reliably to faster speeds. It was "the cream-puff era," says Gary Smith, chief analyst at Gartner Dataquest (IT) in San Jose, Calif. Today, though, circuits are packed so closely that chips are heating up, and performance is starting to suffer. That's one reason giants such as Intel Corp., No. 52 on this year's Info Tech 100, and IBM, No. 44, have fallen behind schedule in launching new generations of microprocessors in recent years.
>
> Even so, chipmakers think they can still pull off a few more generations of shrinking before they hit the wall. They're trying new materials and production tools, and most experts see an orderly progression deep into nanotechnology. Today's circuit lines measure about 90 nanometers in width --- or 90 billionths of a meter. This year and next they'll go down to 65 nm, then 45 nm by 2010, 32 nm by 2013, and 22 nm by 2016, says International Technology Roadmap for Semiconductors, an industry research group. After that, says Paolo A. Gargini, Intel's director for technology strategy, "it's unclear what will come next."

Computer technology is unique in that it has not yet reached the point of diminishing returns, but technology in and of itself most certainly has. Our greatest inventiveness is behind us, not in front of us. Technological innovations will continue to be made, but they will continue to be more rare, more modest, and more expensive. Eventually, even computer technology will suffer this fate, for it, too, is subject to diminishing returns. This means that the likelihood of a "techno-fix" is small, and growing smaller.

Ultimately, though, technology can never stop collapse because collapse is *caused* by greater complexity, and technology is one facet of complexity. The diminishing marginal returns of complexity make a society susceptible to all manner of various proximate causes for collapse, including invasion, ecological devastation, and others. Technological solutions address the proximate causes of collapse, but they do so only by exascerbating the ultimate cause of collapse, by introducing still greater complexity.

Technology is part of the problem we face, not because technology is, in itself, "bad," but because the accumulated unintended consequences of those technologies--especially Jevons Paradox--have continued to hound us. Technology can provide momentary relief or put off the inevitable, but only by compounding the problem still further. The crisis of too much complexity can never be solved by creating still more complexity, just as you can't save your burning house by spraying gasoline on it. Ultimately, what we face is a systemic problem. No technical solution is possible to systemic problems; they can only be solved by changing the system.
